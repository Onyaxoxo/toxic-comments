{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Onyaxoxo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import string \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer \n",
    "nltk.download('punkt')\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.metrics import plot_precision_recall_curve \n",
    "import numpy as np \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./labeled.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14412, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"toxic\"] = df[\"toxic\"].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n      1\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...      1\n",
       "2                          Собаке - собачья смерть\\n      1\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...      1\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9586\n",
       "1    4826\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Верблюдов-то за что? Дебилы, бл...\n",
      "\n",
      "Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
      "\n",
      "Собаке - собачья смерть\n",
      "\n",
      "Страницу обнови, дебил. Это тоже не оскорбление, а доказанный факт - не-дебил про себя во множественном числе писать не будет. Или мы в тебя верим - это ты и твои воображаемые друзья?\n",
      "\n",
      "тебя не убедил 6-страничный пдф в том, что Скрипалей отравила Россия? Анализировать и думать пытаешься? Ватник что ли?)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in df[df[\"toxic\"] == 1][\"comment\"].head(5):\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В шапке были ссылки на инфу по текущему фильму марвел. Эти ссылки были заменены на фразу Репортим брипидора, игнорируем его посты. Если этого недостаточно, чтобы понять, что модератор абсолютный неадекват, и его нужно лишить полномочий, тогда эта борда пробивает абсолютное дно по неадекватности.\n",
      "\n",
      "Почитайте посты у этого автора,может найдете что нибудь полезное. Надеюсь помог) https: pikabu.ru story obyichnyie budni dezsluzhbyi 4932098\n",
      "\n",
      "Про графику было обидно) я так то проходил все серии гта со второй части по пятую, кроме гта 4. И мне не мешала графика ни в одной из частей. На компе у меня было куча видеокарт. Начиная с 32мб RIVA TNT и заканчивая 2Гб 560Ti на которой я спокойно играю который год в танки, гта5, ведьмака3 купил на распродаже и начал проходить. Да, не на ультрах. С пониженными текстурами. И не мешает. Я не понимаю дрочева на графике, требовать графику уровня плойки 4 минимум. Мне надо чтобы глаза не резало, только и всего. По поводу управления, мне не хватает переходника на type c. У меня джойстик есть от иксбокса360. Потенциала в мобильных играх достаточно чтобы забить кнопки как забивались в той же NFS MW в 2005. Не самая плохая игра была.\n",
      "\n",
      "https: pp.userapi.com c848520 v848520411 11627b cOhWqFbGjWE.jpg\n",
      "\n",
      "Возьмём как пример Россию, западноевропейские страны и США. Идёт метисация, сознательная политика замещения белого населения на пришлое черно-коричневое. Идёт создание новой расы метисов, исламизация и почернение. В крупных городах половина населения - выходцы из ебеней Мексики, Африки, Ближнего Востока, а в случае с Россией - Кавказа и Средней Азии. Этнические ниггеро-арабские гетто верят на хую законы как хотят, чудовищная по масштабам этническая преступность. Говорить о миграции и тем более затрагивать тему замещения коренного населения властями нельзя, иначе бутылка. Свобода слова тут не для вас, молодой человек. При этом говорить о том, что белые должны вымереть, и это нормально - можно. Белые официально вымирают ведётся пропаганда так или иначе направленная на снижение рождаемости белого населения. Феминизм, ЛГБТ, чайлдфри. Каждая женщина в Швеции - леволиберальная феминистка, это страна победившего феминизма. Что сегодня там происходит - страшно делается. Пропагандируются смешанные браки, межрасовые браки, пропагандируется превосходство детей-метисов. Идёт демонизация белых и пропаганда превосходства чёрных и смуглых мужчин, форс отношений белая женщина смуглый чёрный мужчина-мигрант. Как результат - всё больше чернильниц, всё больше смешанных браков, всё больше небелых метисов. Белые женщины просто не хотят контактировать с мужчинами своей нации и расы, наделяя их самыми плохими качествами и обожествляя черных. При этом большинство белых не считает завоз чурок чем-то плохим, наоборот, относятся к ним толерантно. Проводится политика насаждения толерантности, мультикультурализма, политкорректности и космополитизма. Набирающее популярность даже в России SJW - это вообще отдельная тема для обсуждения. Всё вышеперечисленное относится к сильнейшим когда-то странам, бывшим империям, нагибающим слабых. Сегодня происходит так, что бывшие империи в прямом смысле деградируют, вырождаются и вымирают, а место сильнейших когда-то, господствующих народов, занимают те, кого когда-то колонизировали. Во Франции к 2080 уже будут доминировать негры и арабы, в России - кавказцы и выходцы из средней Азии, в Великобритании - индийцы, негры, арабы, пакистанцы, etc. А в маленьких, нейтральных странах, вроде Словении или Беларуси, Литвы или Чехии, Румынии или Эстонии - всё пучком. Им вымирание не грозит, они остаются и будут оставаться белыми. Более того, у них ведётся политика, направленная на сохранение традиционных ценностей и культуры коренного населения. Они сказали беженцам нет . В Польшу, например, русскому или украинцу гораздо легче переехать и остаться, чем арабу или африканцу. В Германии ситуация противоположная, белых там не ждут. Польша, Чехия, Словакия, Венгрия, Словения, Хорватия, Сербия, БиГ, Черногория, Македония, Греция, Болгария, Румыния, Молдова, Украина, Беларусь, Литва, Латвия, Эстония - вот Европа будущего. Скандинавия, Южная, Западная Европа, а также Россия - лишатся коренного населения и своей культуры.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in df[df[\"toxic\"] == 0][\"comment\"].head(5):\n",
    "    print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    324\n",
       "1    176\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9262\n",
       "1    4650\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель логистической регрессии\n",
    "1. разбивка комментария по пробелам и знакам пунктуации\n",
    "2. удаляется пунктуация \n",
    "3. удаление стоп-слова\n",
    "4. стемминг. (все слова с нижнем регистром и без окончаний)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_example = df.iloc[1][\"comment\"]\n",
    "tokens = word_tokenize(sentence_example, language=\"russian\")\n",
    "tokens_without_punctuation =[i for i in tokens if i not in string.punctuation]\n",
    "russian_stop_words = stopwords.words(\"russian\")\n",
    "tokens_without_stop_words_and_punctuation = [i for i in tokens_without_punctuation if i not in russian_stop_words]\n",
    "snowball = SnowballStemmer(language=\"russian\")\n",
    "stemmed_tokens = [snowball.stem(i) for i in tokens_without_stop_words_and_punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: Хохлы, это отдушина затюканого россиянина, мол, вон, а у хохлов еще хуже. Если бы хохлов не было, кисель их бы придумал.\n",
      "\n",
      "-------------------------------------\n",
      "Токеныт: ['Хохлы', ',', 'это', 'отдушина', 'затюканого', 'россиянина', ',', 'мол', ',', 'вон', ',', 'а', 'у', 'хохлов', 'еще', 'хуже', '.', 'Если', 'бы', 'хохлов', 'не', 'было', ',', 'кисель', 'их', 'бы', 'придумал', '.']\n",
      "-------------------------------------\n",
      "Токены без пунктуации: ['Хохлы', 'это', 'отдушина', 'затюканого', 'россиянина', 'мол', 'вон', 'а', 'у', 'хохлов', 'еще', 'хуже', 'Если', 'бы', 'хохлов', 'не', 'было', 'кисель', 'их', 'бы', 'придумал']\n",
      "-------------------------------------\n",
      "Токены без пунктуации и стоп слов: ['Хохлы', 'это', 'отдушина', 'затюканого', 'россиянина', 'мол', 'вон', 'хохлов', 'хуже', 'Если', 'хохлов', 'кисель', 'придумал']\n",
      "-------------------------------------\n",
      "ТОкены после стемминга: ['хохл', 'эт', 'отдушин', 'затюкан', 'россиянин', 'мол', 'вон', 'хохл', 'хуж', 'есл', 'хохл', 'кисел', 'придума']\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Исходный текст: {sentence_example}\")\n",
    "print(\"-------------------------------------\")\n",
    "print(f\"Токеныт: {tokens}\")\n",
    "print(\"-------------------------------------\")\n",
    "print(f\"Токены без пунктуации: {tokens_without_punctuation}\")\n",
    "print(\"-------------------------------------\")\n",
    "print(f\"Токены без пунктуации и стоп слов: {tokens_without_stop_words_and_punctuation}\")\n",
    "print(\"-------------------------------------\")\n",
    "print(f\"Токены после стемминга: {stemmed_tokens}\")\n",
    "print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer(language=\"russian\")\n",
    "russian_stop_words = stopwords.words(\"russian\")\n",
    "\n",
    "def tokenize_sentence(sentence: str, remove_stop_words: bool = True):\n",
    "    tokens = word_tokenize(sentence, language=\"russian\")\n",
    "    tokens = [i for i in tokens if i not in string.punctuation]\n",
    "    if remove_stop_words:\n",
    "        tokens = [i for i in tokens if i not in russian_stop_words]\n",
    "    tokens = [snowball.stem(i) for i in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize_sentence(sentence_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidf векторизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.fit_transform(train_df[\"comment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели логистической регрессии.\n",
    "random_state=0 - воспроизводимые результаты \n",
    "метод fit используется для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =LogisticRegression(random_state=0)\n",
    "model.fit(features, train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'У моего дяди было тоже самое, лечили гастрит, умер от рака. У нас диагностов нет.\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"comment\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline ([\n",
    "    (\"vectorizer\", TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
    "    (\"model\", LogisticRegression(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function <lambda> at 0x0000023871B03A68>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=0,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.fit(train_df[\"comment\"], train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.predict([\"эх, как же хорошо на улице\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.predict([\"нахрен оно тебе надо?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true=test_df[\"toxic\"], y_pred=model_pipeline.predict(test_df[\"comment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6477272727272727"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true=test_df[\"toxic\"], y_pred=model_pipeline.predict(test_df[\"comment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, thresholds = precision_recall_curve(y_true=test_df[\"toxic\"], probas_pred=model_pipeline.predict_proba(test_df[\"comment\"])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay at 0x23871e42bc8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_precision_recall_curve(estimator=model_pipeline, X=test_df[\"comment\"], y=test_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "попробуем найти precision > 0.95 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
       "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282,\n",
       "        283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,\n",
       "        296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308,\n",
       "        309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
       "        322, 323, 324, 325, 326], dtype=int64),)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(prec > 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6819051944678692"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds[257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558823529411765"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true=test_df[\"toxic\"], y_pred=model_pipeline.predict_proba(test_df[\"comment\"])[:, 1] > thresholds[257])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3693181818181818"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true=test_df[\"toxic\"], y_pred=model_pipeline.predict_proba(test_df[\"comment\"])[:, 1] > thresholds[257])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшаем параметры с помощью Greedearch. Поменяем коэффициент регуляризации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipeline = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
    "    (\"model\", \n",
    "     GridSearchCV(\n",
    "        LogisticRegression(random_state=0),\n",
    "        param_grid={'C': [0.1, 1, 10.]},\n",
    "        cv=3,\n",
    "         verbose=4\n",
    "        )\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................... C=0.1, score=0.686, total=   0.1s\n",
      "[CV] C=0.1 ...........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=0.1, score=0.689, total=   0.1s\n",
      "[CV] C=0.1 ...........................................................\n",
      "[CV] ............................... C=0.1, score=0.686, total=   0.1s\n",
      "[CV] C=1 .............................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=1, score=0.837, total=   0.3s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.835, total=   0.2s\n",
      "[CV] C=1 .............................................................\n",
      "[CV] ................................. C=1, score=0.835, total=   0.3s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=10.0, score=0.867, total=   0.5s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=10.0, score=0.861, total=   0.5s\n",
      "[CV] C=10.0 ..........................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............................. C=10.0, score=0.862, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=0,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False),\n",
       "                              iid='deprecated', n_jobs=None,\n",
       "                              param_grid={'C': [0.1, 1, 10.0]},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=4))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipeline.fit(train_df[\"comment\"], train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline_c_10 = Pipeline ([\n",
    "    (\"vectorizer\", TfidfVectorizer(tokenizer=lambda x: tokenize_sentence(x, remove_stop_words=True))),\n",
    "    (\"model\", LogisticRegression(random_state=0, C=10.))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Soft\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function <lambda> at 0x0000023871F4FDC8>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=10.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=0,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_c_10.fit(train_df[\"comment\"], train_df[\"toxic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_c_10, rec_c_10, thresholds_c_10 = precision_recall_curve(y_true=test_df[\"toxic\"], probas_pred=model_pipeline_c_10.predict_proba(test_df[\"comment\"])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
       "        265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "        278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
       "        291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
       "        304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "        317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "        330, 331, 332, 333, 334, 335, 336, 337, 338], dtype=int64),)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(prec_c_10 > 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9529411764705882"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true=test_df[\"toxic\"], y_pred=model_pipeline_c_10.predict_proba(test_df[\"comment\"])[:, 1] > thresholds_c_10[252])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4602272727272727"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true=test_df[\"toxic\"], y_pred=model_pipeline_c_10.predict_proba(test_df[\"comment\"])[:, 1] > thresholds_c_10[252])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
